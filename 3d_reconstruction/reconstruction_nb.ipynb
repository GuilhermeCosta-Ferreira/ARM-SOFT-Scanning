{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9053373f",
   "metadata": {},
   "source": [
    "# 3D Reconstruction\n",
    "Now that we have the silhuettes we can now extract the visual hull of the object. Do so we need the camera intrinsic parameters and the extrinsic paramters. Our simulation pipeline already provides us with a json file for that. A python script then can be ran to extract the camera intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe259a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.camera_data import CamerasData\n",
    "from src.scans import Scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ecaf9",
   "metadata": {},
   "source": [
    "## 1. Data Classes\n",
    "To do the reconstruction we need to organize our data into clear but usefull classes. This will include our Camera Data (`CameraData`) and our Pictures (`Scans`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7871d43",
   "metadata": {},
   "source": [
    "### 1.1. Camera Data\n",
    "For the reconstruction we need:\n",
    "- Camera Intrinsics\n",
    "- Extrinsics Parameters\n",
    "\n",
    "The camera intrinsics are defined by the matrix K and the extrinsics are defined by the individual camera positions (4x4 matrix). All of this is managed by the class ```CameraData```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bc07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_data = CamerasData(\"../blender_simulator/simulated_frames/dataset_d30/camera_intrinsics.json\", \"../blender_simulator/simulated_frames/dataset_d30/transforms_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eacbd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Matrix:\n",
      "[[2.66666667e+03 0.00000000e+00 9.60000000e+02]\n",
      " [0.00000000e+00 2.25000000e+03 5.40000000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      "Extrinsic Matrix of Camera 0\n",
      "[[ 9.99992847e-01  5.45056282e-05  3.79700959e-03  0.00000000e+00]\n",
      " [ 3.79740074e-03 -1.43533014e-02 -9.99889851e-01 -1.00000000e+00]\n",
      " [-3.63797881e-12  9.99897003e-01 -1.43534066e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n",
      "With shape: (12, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"K Matrix:\\n{camera_data.K}\\n\")\n",
    "print(f'Extrinsic Matrix of Camera 0\\n{camera_data.get_camera_extrinsics(0)}\\n')\n",
    "print(f'With shape: {camera_data.extrinsics_array.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46c723",
   "metadata": {},
   "source": [
    "**Projection Matrix**<br>\n",
    "By combining both matrices we can have the projection matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30295bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection Matyrix of Camera 0\n",
      "[[ 2.66664759e+03  9.60046471e+02 -3.65391145e+00  0.00000000e+00]\n",
      " [ 8.54415167e+00  5.07649454e+02 -2.25750300e+03 -2.25000000e+03]\n",
      " [-3.63797881e-12  9.99897003e-01 -1.43534066e-02  0.00000000e+00]]\n",
      "\n",
      "With shape: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "P = camera_data.P(0)\n",
    "\n",
    "print(f'Projection Matyrix of Camera 0\\n{P}\\n')\n",
    "print(f'With shape: {P.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af00fd5",
   "metadata": {},
   "source": [
    "## 1.2 Scans\n",
    "Scans should have all the segemntations from the pictures taken. It holds the data as a binary array [0 or 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3ea7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scans = Scans(\"../3d_reconstruction/figures/reconstruction_d30/segmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8545879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scans: 12\n",
      "Dimension of each scan: (1080, 1920)\n",
      "Values in the first scan: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of scans: {scans.nr_positions}\")\n",
    "print(f\"Dimension of each scan: {scans.scan_shape}\")\n",
    "print(f\"Values in the first scan: {np.unique(scans.scan(0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74f158",
   "metadata": {},
   "source": [
    "## Convex Hull\n",
    "This will take the data and apply the convex hull algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab964d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d-reconstruction-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
